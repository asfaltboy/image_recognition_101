{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_recognition_101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "czBSxKn2InwI",
        "MfGrdmueInwL",
        "zfio49jmInwO",
        "1sHytmvoInwP",
        "d_sWCqvTInwS",
        "EqxN0qYtInwU",
        "STIo8CtTInwV",
        "qxRduaycInwX",
        "nB3amMb3Inwa",
        "HdnRiOX_Inwc",
        "q-E3hfv3Inwf",
        "ZFCkoLs6Inwh",
        "5V7ai0k3Inwj",
        "hYLIdCVbInwn",
        "6qsdgzcdInwq",
        "iBekC-ioInwt",
        "OwDuZp1oInwx",
        "Re--2gV-Inwx",
        "GUN0pHPjInwz",
        "jT5Os_hDInw2",
        "g93pEK8YInw3",
        "BBdP9yUaInw7",
        "U7QuqWt4Inw8",
        "CBizizihInxC",
        "f3MK3aYtInxI",
        "zau67Pj7InxN"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "mPT5OcwAInv5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image recognition 101"
      ]
    },
    {
      "metadata": {
        "id": "ERS8FpZAInv6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Working with images"
      ]
    },
    {
      "metadata": {
        "id": "CnbEmODaeYoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone http://github.com/phankiewicz/image_recognition_101.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzkyNmiiInv7",
        "colab_type": "code",
        "outputId": "e257d06d-5f4d-4b81-f238-74d87e3da86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3132
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -r image_recognition_101/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ignoring appnope: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Requirement already satisfied: attrs==19.1.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: backcall==0.1.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 3)) (0.1.0)\n",
            "Requirement already satisfied: bleach==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: decorator==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: defusedxml==0.5.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 8)) (0.3)\n",
            "Collecting ipykernel==5.1.0 (from -r image_recognition_101/requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f0be5c5ab335196f5cce96e5b889a4fcf5bfe462eb0acc05cd7e2caf65eb/ipykernel-5.1.0-py3-none-any.whl (113kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 10)) (0.2.0)\n",
            "Collecting ipython==7.4.0 (from -r image_recognition_101/requirements.txt (line 11))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/b5/ca080401b8dbde51a0f4377b4e22ce02b266340a1cda389b6dea702d06d1/ipython-7.4.0-py3-none-any.whl (769kB)\n",
            "\u001b[K    100% |████████████████████████████████| 778kB 20.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 12)) (7.4.2)\n",
            "Requirement already satisfied: jedi==0.13.3 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 13)) (0.13.3)\n",
            "Requirement already satisfied: jinja2==2.10 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 14)) (2.10)\n",
            "Collecting jsonschema==3.0.1 (from -r image_recognition_101/requirements.txt (line 15))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/69/df679dfbdd051568b53c38ec8152a3ab6bc533434fc7ed11ab034bf5e82f/jsonschema-3.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client==5.2.4 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 16)) (5.2.4)\n",
            "Requirement already satisfied: jupyter-console==6.0.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 17)) (6.0.0)\n",
            "Collecting jupyter-contrib-core==0.3.3 (from -r image_recognition_101/requirements.txt (line 18))\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/8f/04a752a8b66a66e7092c035e5d87d2502ac7ec07f9fb6059059b6c0dc272/jupyter_contrib_core-0.3.3-py2.py3-none-any.whl\n",
            "Collecting jupyter-contrib-nbextensions==0.5.1 (from -r image_recognition_101/requirements.txt (line 19))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/f0/6e2c00afda860f655fbf0f795f7310bdbf12122846344dfdc803fc7455d5/jupyter_contrib_nbextensions-0.5.1-py2.py3-none-any.whl (20.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 20.9MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 20)) (4.4.0)\n",
            "Collecting jupyter-highlight-selected-word==0.2.0 (from -r image_recognition_101/requirements.txt (line 21))\n",
            "  Downloading https://files.pythonhosted.org/packages/50/d7/19ab7cfd60bf268d2abbacc52d4295a40f52d74dfc0d938e4761ee5e598b/jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl\n",
            "Collecting jupyter-latex-envs==1.4.6 (from -r image_recognition_101/requirements.txt (line 22))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/15/55805de080d5542f76920364635e96e64d3b37f678befdfe3b16aa154205/jupyter_latex_envs-1.4.6.tar.gz (861kB)\n",
            "\u001b[K    100% |████████████████████████████████| 870kB 20.0MB/s \n",
            "\u001b[?25hCollecting jupyter-nbextensions-configurator==0.4.1 (from -r image_recognition_101/requirements.txt (line 23))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/a3/d72d5f2dc10c5ccf5a6f4c79f636bf071a5ce462dedd07af2f70384db6cb/jupyter_nbextensions_configurator-0.4.1.tar.gz (479kB)\n",
            "\u001b[K    100% |████████████████████████████████| 481kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 24)) (1.0.0)\n",
            "Requirement already satisfied: kiwisolver==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 25)) (1.0.1)\n",
            "Collecting lxml==4.3.3 (from -r image_recognition_101/requirements.txt (line 26))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/8a/5e066949f2b40caac32c7b2a77da63ad304b5fbe869036cc3fe4a198f724/lxml-4.3.3-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: markupsafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 27)) (1.1.1)\n",
            "Requirement already satisfied: matplotlib==3.0.3 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 28)) (3.0.3)\n",
            "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 29)) (0.8.4)\n",
            "Requirement already satisfied: nbconvert==5.4.1 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 30)) (5.4.1)\n",
            "Requirement already satisfied: nbformat==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 31)) (4.4.0)\n",
            "Collecting notebook==5.7.8 (from -r image_recognition_101/requirements.txt (line 32))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/36/89ebfffc9dd8c8dbd81c1ffb53e3d4233ee666414c143959477cb07cc5f5/notebook-5.7.8-py2.py3-none-any.whl (9.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 9.0MB 3.9MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.2 (from -r image_recognition_101/requirements.txt (line 33))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 1.1MB/s \n",
            "\u001b[?25hCollecting opencv-python==3.4.0.14 (from -r image_recognition_101/requirements.txt (line 34))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/d1/732afb3a056d7e7f3af08f3fcb67a7c1ceedd6be941f8e3907da0400c36e/opencv_python-3.4.0.14-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 24.8MB 1.5MB/s \n",
            "\u001b[?25hCollecting opencv-contrib-python==3.4.0.14 (from -r image_recognition_101/requirements.txt (line 35))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7a/7b7cc50ef74554106c51ffe93eec0047b78e461dcdc4d3e0867afa72ee9c/opencv_contrib_python-3.4.0.14-cp36-cp36m-manylinux1_x86_64.whl (30.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 30.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandocfilters==1.4.2 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 36)) (1.4.2)\n",
            "Requirement already satisfied: parso==0.3.4 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 37)) (0.3.4)\n",
            "Requirement already satisfied: pexpect==4.6.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 38)) (4.6.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 39)) (0.7.5)\n",
            "Requirement already satisfied: plotly==3.6.1 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 40)) (3.6.1)\n",
            "Requirement already satisfied: prometheus-client==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 41)) (0.6.0)\n",
            "Collecting prompt-toolkit==2.0.9 (from -r image_recognition_101/requirements.txt (line 42))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K    100% |████████████████████████████████| 337kB 25.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 43)) (0.6.0)\n",
            "Collecting pygments==2.3.1 (from -r image_recognition_101/requirements.txt (line 44))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e5/6d710c9cf96c31ac82657bcfb441df328b22df8564d58d0c4cd62612674c/Pygments-2.3.1-py2.py3-none-any.whl (849kB)\n",
            "\u001b[K    100% |████████████████████████████████| 849kB 21.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing==2.3.1 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 45)) (2.3.1)\n",
            "Requirement already satisfied: pyrsistent==0.14.11 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 46)) (0.14.11)\n",
            "Collecting python-dateutil==2.8.0 (from -r image_recognition_101/requirements.txt (line 47))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 28.9MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.1 (from -r image_recognition_101/requirements.txt (line 48))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\u001b[K    100% |████████████████████████████████| 276kB 27.9MB/s \n",
            "\u001b[?25hCollecting pyzmq==18.0.1 (from -r image_recognition_101/requirements.txt (line 49))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/04/f6f0fa20b698b29c6e6b1d6b4b575c12607b0abf61810aab1df4099988c6/pyzmq-18.0.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.1MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: qtconsole==4.4.3 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 50)) (4.4.3)\n",
            "Requirement already satisfied: scikit-learn==0.20.3 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 51)) (0.20.3)\n",
            "Collecting scipy==1.2.1 (from -r image_recognition_101/requirements.txt (line 52))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 24.8MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: send2trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 53)) (1.5.0)\n",
            "Collecting six==1.12.0 (from -r image_recognition_101/requirements.txt (line 54))\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: terminado==0.8.2 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 55)) (0.8.2)\n",
            "Requirement already satisfied: testpath==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 56)) (0.4.2)\n",
            "Collecting tornado==6.0.2 (from -r image_recognition_101/requirements.txt (line 57))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/3f/5f89d99fca3c0100c8cede4f53f660b126d39e0d6a1e943e95cc3ed386fb/tornado-6.0.2.tar.gz (481kB)\n",
            "\u001b[K    100% |████████████████████████████████| 491kB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets==4.3.2 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 58)) (4.3.2)\n",
            "Requirement already satisfied: wcwidth==0.1.7 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 59)) (0.1.7)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 60)) (0.5.1)\n",
            "Requirement already satisfied: widgetsnbextension==3.4.2 in /usr/local/lib/python3.6/dist-packages (from -r image_recognition_101/requirements.txt (line 61)) (3.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.4.0->-r image_recognition_101/requirements.txt (line 11)) (40.9.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly==3.6.1->-r image_recognition_101/requirements.txt (line 40)) (3.0.4)\n",
            "Building wheels for collected packages: jupyter-latex-envs, jupyter-nbextensions-configurator, pyyaml, tornado\n",
            "  Building wheel for jupyter-latex-envs (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0d/71/2a/164491997299b9f2479a251e254323fe35d946779e18f27956\n",
            "  Building wheel for jupyter-nbextensions-configurator (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/15/df/fe/2a74fe34709e7fdc5ae153a768675d9fda93cc7d5133ed1fb0\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/61/7e/7a/5e02e60dc329aef32ecf70e0425319ee7e2198c3a7cf98b4a2\n",
            "Successfully built jupyter-latex-envs jupyter-nbextensions-configurator pyyaml tornado\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement notebook~=5.2.0, but you'll have notebook 5.7.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 6.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdopamine-rl 1.0.5 has requirement opencv-python>=3.4.1.15, but you'll have opencv-python 3.4.0.14 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tornado, pygments, six, prompt-toolkit, ipython, ipykernel, jsonschema, pyzmq, notebook, jupyter-contrib-core, lxml, jupyter-latex-envs, pyyaml, jupyter-nbextensions-configurator, jupyter-highlight-selected-word, jupyter-contrib-nbextensions, numpy, opencv-python, opencv-contrib-python, python-dateutil, scipy\n",
            "  Found existing installation: tornado 4.5.3\n",
            "    Uninstalling tornado-4.5.3:\n",
            "      Successfully uninstalled tornado-4.5.3\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: six 1.11.0\n",
            "    Uninstalling six-1.11.0:\n",
            "      Successfully uninstalled six-1.11.0\n",
            "  Found existing installation: prompt-toolkit 1.0.15\n",
            "    Uninstalling prompt-toolkit-1.0.15:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.15\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Found existing installation: ipykernel 4.6.1\n",
            "    Uninstalling ipykernel-4.6.1:\n",
            "      Successfully uninstalled ipykernel-4.6.1\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: pyzmq 17.0.0\n",
            "    Uninstalling pyzmq-17.0.0:\n",
            "      Successfully uninstalled pyzmq-17.0.0\n",
            "  Found existing installation: notebook 5.2.2\n",
            "    Uninstalling notebook-5.2.2:\n",
            "      Successfully uninstalled notebook-5.2.2\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: opencv-python 3.4.5.20\n",
            "    Uninstalling opencv-python-3.4.5.20:\n",
            "      Successfully uninstalled opencv-python-3.4.5.20\n",
            "  Found existing installation: opencv-contrib-python 3.4.3.18\n",
            "    Uninstalling opencv-contrib-python-3.4.3.18:\n",
            "      Successfully uninstalled opencv-contrib-python-3.4.3.18\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "  Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "Successfully installed ipykernel-5.1.0 ipython-7.4.0 jsonschema-3.0.1 jupyter-contrib-core-0.3.3 jupyter-contrib-nbextensions-0.5.1 jupyter-highlight-selected-word-0.2.0 jupyter-latex-envs-1.4.6 jupyter-nbextensions-configurator-0.4.1 lxml-4.3.3 notebook-5.7.8 numpy-1.16.2 opencv-contrib-python-3.4.0.14 opencv-python-3.4.0.14 prompt-toolkit-2.0.9 pygments-2.3.1 python-dateutil-2.8.0 pyyaml-5.1 pyzmq-18.0.1 scipy-1.2.1 six-1.12.0 tornado-6.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "dateutil",
                  "ipykernel",
                  "numpy",
                  "prompt_toolkit",
                  "pygments",
                  "scipy",
                  "six",
                  "tornado",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JsD5u_zAInv9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import IPython\n",
        "import numpy as np\n",
        "import os\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "sift = cv2.xfeatures2d.SIFT_create()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRloTwGiLbH1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "INPUT_BASE_PATH = os.path.join('image_recognition_101', 'input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kxkWf69TInwA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GREG_IMAGE_PATH = os.path.join(INPUT_BASE_PATH, 'greg.png')\n",
        "SUDOKU_IMAGE_PATH = os.path.join(INPUT_BASE_PATH, 'sudoku.jpg')\n",
        "MEMESFUNNY_IMAGE_PATH = os.path.join(INPUT_BASE_PATH, 'memesfunny.png')\n",
        "LOGO_IMAGE_PATH = os.path.join(INPUT_BASE_PATH, 'logo.png')\n",
        "LOGO_MULTIPLE_SCREENSHOT_IMAGE_PATH = os.path.join(INPUT_BASE_PATH, 'logo_multiple_screenshot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpTz_zf8AM4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def configure_plotly_browser_state():\n",
        "  display(\n",
        "      IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "def display_plotly_image(image):\n",
        "  configure_plotly_browser_state()\n",
        "  plotly.offline.init_notebook_mode(connected=False)\n",
        "\n",
        "  img_height, img_width, *_ = image.shape\n",
        "  pil_im = Image.fromarray(image)\n",
        "\n",
        "\n",
        "  scale_factor = 400/img_width\n",
        "\n",
        "  layout = go.Layout(\n",
        "      xaxis = go.layout.XAxis(\n",
        "          visible = False,\n",
        "          range = [0, img_width*scale_factor]),\n",
        "      yaxis = go.layout.YAxis(\n",
        "          visible=False,\n",
        "          range = [0, img_height*scale_factor],\n",
        "          scaleanchor = 'x'),\n",
        "      width = img_width*scale_factor,\n",
        "      height = img_height*scale_factor,\n",
        "      margin = {'l': 0, 'r': 0, 't': 0, 'b': 0},\n",
        "      images = [go.layout.Image(\n",
        "          x=0,\n",
        "          sizex=img_width*scale_factor,\n",
        "          y=img_height*scale_factor,\n",
        "          sizey=img_height*scale_factor,\n",
        "          xref=\"x\",\n",
        "          yref=\"y\",\n",
        "          opacity=1.0,\n",
        "          layer=\"below\",\n",
        "          sizing=\"stretch\",\n",
        "          source=pil_im)]\n",
        "  )\n",
        "  fig = go.Figure(data=[{\n",
        "      'x': [0, img_width*scale_factor], \n",
        "      'y': [0, img_height*scale_factor], \n",
        "      'mode': 'markers',\n",
        "      'marker': {'opacity': 0}}],layout = layout)\n",
        "  plotly.offline.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwH5HQ6XInwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_image(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    display_plotly_image(image)\n",
        "    \n",
        "    \n",
        "def display_greyscale_image(image):\n",
        "    display_plotly_image(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciHXYwhdInwD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "color_image = cv2.imread(GREG_IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "print(color_image.shape)\n",
        "display_image(color_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tD3NhzO0InwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "color_image[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "czBSxKn2InwI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 1\n",
        "\n",
        "OpenCV constants for the exercise:\n",
        "+ IMREAD_COLOR\n",
        "+ IMREAD_GRAYSCALE\n",
        "+ IMREAD_UNCHANGED\n",
        "+ IMREAD_REDUCED_GRAYSCALE_2\n",
        "+ IMREAD_REDUCED_COLOR_2\n",
        "+ IMREAD_REDUCED_GRAYSCALE_4\n",
        "+ IMREAD_REDUCED_COLOR_4\n",
        "+ IMREAD_REDUCED_GRAYSCALE_8\n",
        "+ IMREAD_REDUCED_COLOR_8\n",
        "\n",
        "Try to read greg image with different input flags listed above.\n",
        "Take a look at the results using next cell.\n",
        "Don't forget to check what is the shape of your newly read image and what is the value for specific pixel"
      ]
    },
    {
      "metadata": {
        "id": "du7pzRtEInwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_image = cv2.imread(GREG_IMAGE_PATH, cv2.IMREAD_GRAYSCALE)\n",
        "display_greyscale_image(input_image)\n",
        "input_image[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MfGrdmueInwL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Blurring"
      ]
    },
    {
      "metadata": {
        "id": "m7mP0xD4InwM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread(GREG_IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "blurred_image_10 = cv2.blur(image, (50, 10))\n",
        "display_image(blurred_image_10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfio49jmInwO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 2\n",
        "Try out different kernel values for `blur` function."
      ]
    },
    {
      "metadata": {
        "id": "1sHytmvoInwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Edge detection"
      ]
    },
    {
      "metadata": {
        "id": "SdXksxFXInwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread(GREG_IMAGE_PATH, cv2.IMREAD_GRAYSCALE)\n",
        "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
        "enhanced_laplacian = laplacian.copy()\n",
        "enhanced_laplacian[enhanced_laplacian > 10] = 255\n",
        "display_greyscale_image(enhanced_laplacian)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_sWCqvTInwS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 3\n",
        "In the next cell read image of the sudoku puzzle. Try to detect edges using Laplacian method.\n",
        "\n",
        "Compare it with Sobel operator using following function:\n",
        "\n",
        "`cv2.Sobel(input_image, cv2.CV_64F, 1, 0, ksize=ksize_parameter)`\n",
        "\n",
        "Play around with `ksize` parameter for better results.\n",
        "\n",
        "**Remember that `ksize` parameter can only be odd number from range -1 to 31**"
      ]
    },
    {
      "metadata": {
        "id": "9cPSdOpzInwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sudoku_image = cv2.imread(SUDOKU_IMAGE_PATH, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "edge_detection_image = cv2.Sobel(sudoku_image, cv2.CV_64F, 0, 1, ksize=-1)\n",
        "display_greyscale_image(edge_detection_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EqxN0qYtInwU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature detection"
      ]
    },
    {
      "metadata": {
        "id": "STIo8CtTInwV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keypoints detection using SIFT algorithm"
      ]
    },
    {
      "metadata": {
        "id": "LzojPvCkInwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread(GREG_IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "keypoints = sift.detect(image, None)\n",
        "image_with_keypoints = cv2.drawKeypoints(image, keypoints, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
        "display_image(image_with_keypoints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxRduaycInwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keypoints detection using ORB algorithm"
      ]
    },
    {
      "metadata": {
        "id": "eGVIcQj4InwY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "orb = cv2.ORB_create()\n",
        "keypoints = orb.detect(image, None)\n",
        "image_with_keypoints = cv2.drawKeypoints(image, keypoints, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
        "display_image(image_with_keypoints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nB3amMb3Inwa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 4\n",
        "\n",
        "Flags for drawKeypoints:\n",
        "+ DRAW_MATCHES_FLAGS_DEFAULT *only center point*\n",
        "+ DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS *center point with keypoint size and orientation*\n",
        "+ DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS *single keypoints will not be drawn*\n",
        "\n",
        "Observe changes in result image using different flags for drawKeypoints function.\n",
        "\n",
        "Try to analyze what are the characteristic features of keypoints that were selected by algorithm."
      ]
    },
    {
      "metadata": {
        "id": "mnLCjI-XInwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread(GREG_IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "keypoints = sift.detect(image, None)\n",
        "image_with_keypoints_with_different_flags = cv2.drawKeypoints(image, keypoints, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "display_image(image_with_keypoints_with_different_flags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdnRiOX_Inwc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature matching"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "nfdxbgpXInwd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "greg_image = cv2.imread(GREG_IMAGE_PATH)\n",
        "memesfunny_image = cv2.imread(MEMESFUNNY_IMAGE_PATH)\n",
        "\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "greg_keypoints, greg_descriptors = sift.detectAndCompute(greg_image, None)\n",
        "memesfunny_keypoints, memesfunny_descriptors = sift.detectAndCompute(memesfunny_image, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-E3hfv3Inwf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 5\n",
        "Display keypoints found for memesfunny image using `drawKeypoints` function."
      ]
    },
    {
      "metadata": {
        "id": "W1cmA019Inwf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your code goes here\n",
        "memesfunny_image_with_keypoints = cv2.drawKeypoints(memesfunny_image, memesfunny_keypoints, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "display_image(memesfunny_image_with_keypoints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFCkoLs6Inwh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Match"
      ]
    },
    {
      "metadata": {
        "id": "faYwuIs6Inwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bf = cv2.BFMatcher()\n",
        "matches = bf.match(greg_descriptors, memesfunny_descriptors)\n",
        "\n",
        "first_match = matches[0]\n",
        "\n",
        "print(first_match.distance)\n",
        "print(first_match.queryIdx)\n",
        "print(first_match.trainIdx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5V7ai0k3Inwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Displaying matches"
      ]
    },
    {
      "metadata": {
        "id": "ny9HsuALInwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matches = sorted(matches, key = lambda x:x.distance)\n",
        "matches_image = cv2.drawMatches(greg_image, greg_keypoints, memesfunny_image, memesfunny_keypoints, matches[:10], outImg=np.array([]), flags=2)\n",
        "display_image(matches_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hYLIdCVbInwn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Knn matches"
      ]
    },
    {
      "metadata": {
        "id": "VibM5r73Inwo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matches = bf.knnMatch(greg_descriptors, memesfunny_descriptors, k=2)\n",
        "match, nearest_neighbour_match = matches[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6qsdgzcdInwq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 6\n",
        "Display distance attribute for both `match` and `nearest_neighbour_match`.\n",
        "\n",
        "Compare those values. What do they tell us about specific match?"
      ]
    },
    {
      "metadata": {
        "id": "l8R4QWtIInwq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(match.distance)\n",
        "print(nearest_neighbour_match.distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBekC-ioInwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Lowe's ratio"
      ]
    },
    {
      "metadata": {
        "id": "ypMg7Ol1Inwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lowe_ratio = 0.8\n",
        "\n",
        "good_matches = []\n",
        "for best_match, second_best_match in matches:\n",
        "    if best_match.distance < lowe_ratio * second_best_match.distance:\n",
        "        good_matches.append(best_match)\n",
        "        \n",
        "knn_matches_image = cv2.drawMatchesKnn(greg_image, greg_keypoints, memesfunny_image, memesfunny_keypoints, [[match] for match in good_matches], outImg=np.array([]), flags=2)\n",
        "display_image(knn_matches_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OwDuZp1oInwx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 7\n",
        "Play around with `lowe_ratio` value.\n",
        "\n",
        "How those changes influence number of found good matches?"
      ]
    },
    {
      "metadata": {
        "id": "Re--2gV-Inwx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Homography"
      ]
    },
    {
      "metadata": {
        "id": "_a8Pt8MSInwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change `lowe_ratio` to 0.75 again and rerun previous cell"
      ]
    },
    {
      "metadata": {
        "id": "GUN0pHPjInwz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display found object"
      ]
    },
    {
      "metadata": {
        "id": "8ezE0pjvInw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "greg_points = np.float32(\n",
        "    [greg_keypoints[match.queryIdx].pt for match in good_matches]\n",
        ").reshape(-1,1,2)\n",
        "memesfunny_points = np.float32(\n",
        "    [memesfunny_keypoints[match.trainIdx].pt for match in good_matches]\n",
        ").reshape(-1,1,2)\n",
        "\n",
        "transformation_matrix, matches_mask = cv2.findHomography(\n",
        "    greg_points, memesfunny_points, cv2.RANSAC, 5.0\n",
        ")\n",
        "matches_mask = matches_mask.ravel().tolist()\n",
        "\n",
        "\n",
        "height, width, *_ = greg_image.shape\n",
        "points = np.float32([\n",
        "    [0, 0],\n",
        "    [0, height - 1],\n",
        "    [width - 1, height - 1],\n",
        "    [width - 1, 0],\n",
        "]).reshape(-1, 1, 2)\n",
        "transformed_points = cv2.perspectiveTransform(\n",
        "    points, transformation_matrix\n",
        ")\n",
        "\n",
        "homography_image = cv2.polylines(\n",
        "    memesfunny_image,\n",
        "    [np.int32(transformed_points)],\n",
        "    True,\n",
        "    (0, 0, 255), # draw border in green color\n",
        "    3,\n",
        "    cv2.LINE_AA,\n",
        ")\n",
        "display_image(homography_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jT5Os_hDInw2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 8\n",
        "Change params of polylines function above to display border of matched area in red.\n",
        "\n",
        "**Remember that colors in OpenCV are represented in *BGR* color space**"
      ]
    },
    {
      "metadata": {
        "id": "g93pEK8YInw3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display matches"
      ]
    },
    {
      "metadata": {
        "id": "UlW6MqAIInw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "draw_params = dict(\n",
        "    matchColor = (0, 255, 0),\n",
        "    singlePointColor = None,\n",
        "    matchesMask = matches_mask,\n",
        "    flags = 2,\n",
        ")\n",
        "\n",
        "homography_image_with_matches = cv2.drawMatches(\n",
        "    greg_image,\n",
        "    greg_keypoints,\n",
        "    homography_image,\n",
        "    memesfunny_keypoints,\n",
        "    good_matches,\n",
        "    None,\n",
        "    **draw_params,\n",
        ")\n",
        "display_image(homography_image_with_matches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBdP9yUaInw7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 9\n",
        "Change value of `matchesMask` parameter to `[number % 10 == 0 for number in range(len(matches_mask))]`.\n",
        "\n",
        "What changed? How do you think, what is the reason to use mask for matches?"
      ]
    },
    {
      "metadata": {
        "id": "U7QuqWt4Inw8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Flann Based Matcher"
      ]
    },
    {
      "metadata": {
        "id": "sGnJEjOgInw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FLANN_INDEX_KDTREE = 0\n",
        "KNN_MATCH_NEAREST_NEIGHBOURS_NUMBER = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "idJ4zFDTInw-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "search_params = dict(checks=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39FiE5NiInxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flann = cv2.FlannBasedMatcher(index_params, search_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBizizihInxC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multiple Images Matching"
      ]
    },
    {
      "metadata": {
        "id": "5OjQDMcQInxD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MeanShift, estimate_bandwidth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2u8tV4WXInxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_image = cv2.imread(LOGO_IMAGE_PATH)\n",
        "target_image = cv2.imread(LOGO_MULTIPLE_SCREENSHOT_IMAGE_PATH)\n",
        "keypoints1, descriptors1 = sift.detectAndCompute(source_image, None)\n",
        "keypoints2, descriptors2 = sift.detectAndCompute(target_image, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVLm04UMInxH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keypoints2 = np.array(keypoints2)\n",
        "keypoints2_coordinates = np.array([keypoint.pt for keypoint in keypoints2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3MK3aYtInxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Clustering"
      ]
    },
    {
      "metadata": {
        "id": "PfUg6N6rInxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BANDWIDTH_QUANTILE = 0.1\n",
        "NUMBER_OF_SAMPLES = 500\n",
        "\n",
        "bandwidth = estimate_bandwidth(\n",
        "    keypoints2_coordinates, quantile=BANDWIDTH_QUANTILE, n_samples=NUMBER_OF_SAMPLES\n",
        ")\n",
        "mean_shift = MeanShift(bandwidth=bandwidth, bin_seeding=True, cluster_all=True)\n",
        "mean_shift.fit(keypoints2_coordinates)\n",
        "mean_shift_labels = mean_shift.labels_\n",
        "clusters_labels = np.unique(mean_shift_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHUdaeWGInxK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cluster_matches = []\n",
        "for cluster_label in clusters_labels:\n",
        "    cluster_points_indices, = np.where(mean_shift_labels == cluster_label)\n",
        "    keypoints2_cluster = keypoints2[cluster_points_indices]\n",
        "    descriptors2_cluster = descriptors2[cluster_points_indices]\n",
        "\n",
        "    matches = flann.knnMatch(\n",
        "        descriptors1, descriptors2_cluster, k=KNN_MATCH_NEAREST_NEIGHBOURS_NUMBER\n",
        "    )\n",
        "    good_matches = []\n",
        "    lowe_ratio = 0.75\n",
        "    for best_match, second_best_match in matches:\n",
        "        if best_match.distance < lowe_ratio * second_best_match.distance:\n",
        "            good_matches.append(best_match)\n",
        "\n",
        "    cluster_matches.append(((keypoints1, keypoints2_cluster), good_matches))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m36OY7muInxL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MIN_MATCH_COUNT = 10\n",
        "output_image = target_image\n",
        "for (cluster_keypoints1, cluster_keypoints2), matches in cluster_matches:\n",
        "    if len(matches) >= MIN_MATCH_COUNT: \n",
        "        points1 = np.float32(\n",
        "            [cluster_keypoints1[match.queryIdx].pt for match in matches]\n",
        "        ).reshape(-1,1,2)\n",
        "        points2 = np.float32(\n",
        "            [cluster_keypoints2[match.trainIdx].pt for match in matches]\n",
        "        ).reshape(-1,1,2)\n",
        "\n",
        "        transformation_matrix, matches_mask = cv2.findHomography(\n",
        "            points1, points2, cv2.RANSAC, 5.0\n",
        "        )\n",
        "        if transformation_matrix is None:\n",
        "            continue\n",
        "        matches_mask = matches_mask.ravel().tolist()\n",
        "\n",
        "        height, width, *_ = source_image.shape\n",
        "        points = np.float32([\n",
        "            [0, 0],\n",
        "            [0, height - 1],\n",
        "            [width - 1, height - 1],\n",
        "            [width - 1, 0],\n",
        "        ]).reshape(-1, 1, 2)\n",
        "        transformed_points = cv2.perspectiveTransform(\n",
        "            points, transformation_matrix\n",
        "        )\n",
        "\n",
        "        output_image = cv2.polylines(output_image, [np.int32(transformed_points)], True, 255, 3, cv2.LINE_AA)\n",
        "display_image(output_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zau67Pj7InxN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 10\n",
        "Play around with `BANDWIDTH_QUANTILE` constant.\n",
        "\n",
        "Try to match as many lion logos as possible."
      ]
    }
  ]
}